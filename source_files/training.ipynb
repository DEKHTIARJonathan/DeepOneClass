{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link towards reporting gsheet document:\n",
    "https://docs.google.com/spreadsheets/d/1o0O9HGCUABQWF1C6uHw65veY9Axd3pATWwdG2WSpdf8/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters corresponding to gsheet file\n",
    "CLASS_NBR = 6\n",
    "MODE = \"direct\" # \"direct\" or \"cached\"\n",
    "KERNEL = \"linear\" # \"linear\" or \"rbf\"\n",
    "LR = 0.1\n",
    "C = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local parameters\n",
    "BATCH_SIZE = 10\n",
    "CNN_OUTPUT_DIR = os.path.join(\"..\", \"tmp\", \"cnn_output\", \"VGG16\")\n",
    "TARGET_W = 224\n",
    "TRAIN_STEPS = None\n",
    "MODEL_DIR_DIRECT = \"../tmp/estimator_svdd_naive_direct\"\n",
    "MODEL_DIR_CACHED = \"../tmp/estimator_svdd_naive_cached\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import train_cnn_input_fn, test_cnn_input_fn, train_input_fn, test_input_fn\n",
    "\n",
    "# Sanity check\n",
    "train_cnn_input_fn(\n",
    "    CLASS_NBR,\n",
    "    CNN_OUTPUT_DIR\n",
    "), test_cnn_input_fn(\n",
    "    CLASS_NBR,\n",
    "    CNN_OUTPUT_DIR\n",
    "), train_input_fn(\n",
    "    CLASS_NBR,\n",
    "    TARGET_W\n",
    "), test_input_fn(\n",
    "    CLASS_NBR,\n",
    "    TARGET_W\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estimator_svdd_naive import OCClassifier as SVDDClassifier\n",
    "\n",
    "if MODE == \"cached\":\n",
    "    input_fn_train = lambda: train_cnn_input_fn(CLASS_NBR, CNN_OUTPUT_DIR).batch(BATCH_SIZE).repeat()\n",
    "    input_fn_test = lambda: test_cnn_input_fn(CLASS_NBR, CNN_OUTPUT_DIR).batch(BATCH_SIZE)\n",
    "    train_hooks = []\n",
    "    test_hooks = train_hooks\n",
    "    MODEL_DIR = MODEL_DIR_CACHED\n",
    "elif MODE == \"direct\":\n",
    "    from vgg_network import VGG_Network\n",
    "    from estimator_svdd_naive import _LoadPreTrainedWeightsVGG\n",
    "    from data_utils import run_dataset_through_network\n",
    "    \n",
    "    net = VGG_Network(include_FC_head=False)\n",
    "    \n",
    "    def get_train_dataset(net, reuse=False):\n",
    "        dataset = train_input_fn(CLASS_NBR, TARGET_W).batch(BATCH_SIZE)\n",
    "        dataset = run_dataset_through_network(dataset, net, reuse=reuse)\n",
    "        return dataset.repeat()\n",
    "    \n",
    "    def get_test_dataset(net, reuse=False):\n",
    "        dataset = test_input_fn(CLASS_NBR, TARGET_W).batch(BATCH_SIZE)\n",
    "        dataset = dataset.map(lambda img, label: img)\n",
    "        dataset = run_dataset_through_network(dataset, net, reuse=reuse)\n",
    "        return dataset\n",
    "    \n",
    "    input_fn_train = lambda: get_train_dataset(net, reuse=False)\n",
    "    input_fn_test = lambda: get_test_dataset(net, reuse=False)\n",
    "    train_hooks = [_LoadPreTrainedWeightsVGG(net)]\n",
    "    test_hooks = train_hooks\n",
    "    MODEL_DIR = MODEL_DIR_DIRECT\n",
    "else:\n",
    "    raise Exception(\"MODE unknown\")\n",
    "    \n",
    "classifier = SVDDClassifier(\n",
    "    c=C,\n",
    "    kernel=KERNEL,\n",
    "    learning_rate=LR,\n",
    "    model_dir=MODEL_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifier.train(\n",
    "    input_fn=input_fn_train,\n",
    "    steps=TRAIN_STEPS,\n",
    "    hooks=train_hooks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = classifier.predict(\n",
    "    input_fn=input_fn_test,\n",
    "    hooks=test_hooks\n",
    ")\n",
    "\n",
    "predictions_list = list(predictions)\n",
    "predicted_scores = np.asarray(list(map(lambda p: p[\"predicted_scores\"], predictions_list))).astype(np.int32)\n",
    "predicted_classes = np.asarray(list(map(lambda p: p[\"predicted_classes\"], predictions_list))).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predicted_classes)\n",
    "df.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "y_test = []\n",
    "input_fn = test_cnn_input_fn(CLASS_NBR, CNN_OUTPUT_DIR).batch(1)\n",
    "input_fn = input_fn.make_one_shot_iterator().get_next()\n",
    "sess = tf.Session()\n",
    "while True:\n",
    "    try:\n",
    "        data = sess.run(input_fn)\n",
    "        y_test.append(data[1][0])\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break\n",
    "y_test = np.asarray(y_test)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validation import evaluation_summary\n",
    "evaluation_summary(y_test, predicted_classes, plot_cm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
