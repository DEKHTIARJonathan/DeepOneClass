{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primal optimisation with mapped features\n",
    "\n",
    "Here, we apply the same logic as the previous notebook, but we start by mapping the features thanks to a kernel function. \n",
    "\n",
    "The RandomFourrierFeatureMapper is an approximation of the RBG implicit map, which maps to infinite dimensions.\n",
    "\n",
    "Along with our C, two new hyperparameters appear: the map output dimensions and the RFFM stddev.\n",
    "\n",
    "Take note that the center is now in the higher-dimentional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "MAP_DIMS = 2000\n",
    "DIMS = 2\n",
    "INPUTS_NBR = 100\n",
    "FRAC_ERR = 0.0008\n",
    "\n",
    "R = tf.Variable(tf.random_normal([], mean=10), dtype=tf.float32, name=\"Radius\")\n",
    "a = tf.Variable(tf.random_normal([MAP_DIMS], mean=5), dtype=tf.float32, name=\"Center\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, DIMS), name=\"X\")\n",
    "C = tf.constant(1.0/(INPUTS_NBR*FRAC_ERR), dtype=tf.float32)\n",
    "\n",
    "\n",
    "kernel_mapper = tf.contrib.kernel_methods.RandomFourierFeatureMapper(\n",
    "        input_dim=DIMS,\n",
    "        output_dim=MAP_DIMS,\n",
    "        stddev=10,\n",
    "        name=\"rffm\"\n",
    "    )\n",
    "mapped_X = kernel_mapper.map(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint = tf.square(R) - tf.square(tf.norm(mapped_X - a, axis=1))\n",
    "loss = tf.square(R) - C * tf.reduce_sum(tf.minimum(constraint, 0.0))\n",
    "loss = tf.reduce_sum(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train loop is unchanged. Here we added some validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.2 %, Loss:  1.0239, R:  1.0119427643"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.1)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "EPOCHS = 10000\n",
    "\n",
    "x_train = np.random.multivariate_normal(mean=[1., 1.], cov=np.eye(2), size=INPUTS_NBR).astype(np.float32)\n",
    "x_eval = np.vstack([\n",
    "    np.random.multivariate_normal(mean=[1., 1.], cov=np.eye(2), size=950).astype(np.float32),\n",
    "    np.random.multivariate_normal(mean=[10., 10.], cov=np.eye(2), size=50).astype(np.float32),\n",
    "])\n",
    "    \n",
    "    \n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(EPOCHS):\n",
    "    _, l, R1, a1 = sess.run([train, loss, R, a], feed_dict={X: x_train})\n",
    "\n",
    "    towrite = \"\\r{0:4.1f} %, Loss: {1:7.4f}, R: {2:7.4f}\".format(e / EPOCHS * 100, l, R1)\n",
    "    sys.stdout.write(towrite)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the evaluation and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_y = tf.sign(tf.square(R) - tf.square(tf.norm(mapped_X - a, axis=1)))\n",
    "\n",
    "result = sess.run(eval_y, feed_dict={X: x_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ind_normal = result > 0\n",
    "ind_outlier = result < 0\n",
    "plt.plot(x_eval[ind_normal, 0], x_eval[ind_normal, 1], \"x\", label=\"Predicted as normal\")\n",
    "plt.plot(x_eval[ind_outlier, 0], x_eval[ind_outlier, 1], \"x\", label=\"Predicted as outlier\")\n",
    "plt.legend()\n",
    "g = plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
